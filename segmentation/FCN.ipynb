{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louis/anaconda3/envs/dl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "import torchmetrics\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../dataset/'\n",
    "train_dir = data_dir + 'train/'\n",
    "val_dir = data_dir + 'val/'\n",
    "unlabel_dir = data_dir + 'unlabeled/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDataset(Dataset):\n",
    "    def __init__(self, root='../dataset/train/', transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.vid_list = sorted(os.listdir(root))\n",
    "        self.img_list = ['image_' + str(i) + '.png' for i in range(22)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.vid_list) * 22\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        vid_idx = idx // 22\n",
    "        img_idx = idx % 22\n",
    "        # load image\n",
    "        img_path = os.path.join(self.root, self.vid_list[vid_idx], self.img_list[img_idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        # load mask\n",
    "        mask_path = os.path.join(self.root, self.vid_list[vid_idx], 'mask.npy')\n",
    "        target = np.load(mask_path)[img_idx]\n",
    "        # transforms\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.PILToTensor(),\n",
    "    T.ConvertImageDtype(torch.float),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "dataset_train = MaskDataset(transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dataset_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "img, target = next(iter(dataloader))\n",
    "print(img.shape, target.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "brightness = 0.4\n",
    "contrast = 0.4\n",
    "saturation = 0.4\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.RandomResizedCrop(size=(160, 240), scale=(0.8, 1.0)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomVerticalFlip(),\n",
    "    T.ColorJitter(\n",
    "        brightness=0.4,\n",
    "        contrast=0.4,\n",
    "        saturation=0.4,\n",
    "    ),\n",
    "    T.RandomAdjustSharpness(sharpness_factor=5), \n",
    "    T.GaussianBlur(kernel_size=(3, 9), sigma=(0.1, 2)),\n",
    "    T.RandomGrayscale(p=0.1),\n",
    "    # T.PILToTensor(),\n",
    "    # T.ConvertImageDtype(torch.float),\n",
    "    # T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "dataset_train = MaskDataset(transform=transform)\n",
    "dataset_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset_train, batch_size=8, shuffle=True)\n",
    "img, target = next(iter(dataloader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.segmentation.fcn_resnet50(\n",
    "    weights=None,\n",
    "    weights_backbone=models.ResNet50_Weights.IMAGENET1K_V2, \n",
    "    num_classes=49,\n",
    "    aux_loss=True\n",
    ").to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(inputs, target):\n",
    "    losses = {}\n",
    "    for name, x in inputs.items():\n",
    "        losses[name] = nn.functional.cross_entropy(x, target)\n",
    "\n",
    "    if len(losses) == 1:\n",
    "        return losses[\"out\"]\n",
    "\n",
    "    return losses[\"out\"] + 0.5 * losses[\"aux\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_optimize = [\n",
    "    {\"params\": [p for p in model.backbone.parameters() if p.requires_grad]},\n",
    "    {\"params\": [p for p in model.classifier.parameters() if p.requires_grad]},\n",
    "]\n",
    "\n",
    "params = [p for p in model.aux_classifier.parameters() if p.requires_grad]\n",
    "params_to_optimize.append({\"params\": params, \"lr\": lr * 10})\n",
    "\n",
    "optimizer = torch.optim.SGD(params_to_optimize, lr=lr, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "    print(epoch)\n",
    "    for imgs, targets in dataloader:\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "        \n",
    "        output = model(imgs)\n",
    "        loss = criterion(output, targets.long())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(loss.item())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, targets = next(iter(dataloader))\n",
    "# imgs, targets = img.to(device), targets.to(device)\n",
    "\n",
    "outputs = model(imgs.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = outputs['out']\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.cpu().detach().numpy()\n",
    "output_predictions = output.argmax(1)\n",
    "output_predictions.shape\n",
    "bg = torch.zeros_like(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard = torchmetrics.JaccardIndex(task=\"multiclass\", num_classes=49\n",
    "                                    , average='micro'\n",
    "                                    )\n",
    "\n",
    "output_predictions = bg\n",
    "print(jaccard(torch.Tensor(output_predictions), targets).item())\n",
    "\n",
    "s = 0.0\n",
    "for i in range(8):\n",
    "    j = jaccard(torch.Tensor(output_predictions[i]), targets[i]).item()\n",
    "    s += j\n",
    "\n",
    "s / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgs[0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output_predictions[0])\n",
    "output_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(targets[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/Users/louis/Files/deep-learning/Deep-Learning-VQA/segmentation/output/20230427-111232/fcn_resnet50_best.pth'\n",
    "\n",
    "model = models.segmentation.fcn_resnet50(num_classes=49, aux_loss=True)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, targets = next(iter(dataloader))\n",
    "imgs = imgs.to(device)\n",
    "\n",
    "outputs = model(imgs)\n",
    "outs = outputs['out'].cpu().detach().numpy()\n",
    "out_pred = outs.argmax(1)\n",
    "out_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out_pred[0])\n",
    "out_pred.max()\n",
    "np.unique(out_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(targets[0].cpu())\n",
    "np.unique(targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(torch.Tensor(out_pred), targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard = torchmetrics.JaccardIndex(task=\"multiclass\", num_classes=49, \n",
    "                                    # average='micro'\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "imgs, targets = next(iter(dataloader))\n",
    "\n",
    "outputs = model(imgs.to(device))\n",
    "outs = outputs['out'].cpu().detach().numpy()\n",
    "out_pred = outs.argmax(1)\n",
    "out_pred.shape\n",
    "\n",
    "bg = torch.zeros((32, 160, 240))\n",
    "\n",
    "print(jaccard(targets, torch.Tensor(out_pred)).item())\n",
    "print(jaccard(targets, targets).item() )\n",
    "print(jaccard(targets, bg).item() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard(targets, bg).item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7 / 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = os.path.join(train_dir, 'video_0', 'mask.npy')\n",
    "mask = np.load(mask_path)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import functional as F\n",
    "\n",
    "size = 300\n",
    "\n",
    "img = F.resize(img, size)\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.Tensor(mask).unsqueeze(0)\n",
    "print(target.shape)\n",
    "\n",
    "target = F.resize(target, 250, interpolation=transforms.InterpolationMode.NEAREST)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(train_dir, 'video_0', 'image_0.png')\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision import models\n",
    "import copy\n",
    "from lightly.models.modules import BYOLPredictionHead, BYOLProjectionHead\n",
    "from lightly.models.utils import deactivate_requires_grad\n",
    "        \n",
    "\n",
    "class BYOL(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = backbone\n",
    "        self.projection_head = BYOLProjectionHead(2048, 4096, 256)\n",
    "        self.prediction_head = BYOLPredictionHead(256, 4096, 256)\n",
    "\n",
    "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
    "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
    "\n",
    "        deactivate_requires_grad(self.backbone_momentum)\n",
    "        deactivate_requires_grad(self.projection_head_momentum)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(y)\n",
    "        p = self.prediction_head(z)\n",
    "        return p\n",
    "\n",
    "    def forward_momentum(self, x):\n",
    "        y = self.backbone_momentum(x).flatten(start_dim=1)\n",
    "        z = self.projection_head_momentum(y)\n",
    "        z = z.detach()\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50()\n",
    "model = BYOL(nn.Sequential(*list(resnet50.children())[:-1]))\n",
    "\n",
    "path = '/Users/louis/Files/deep-learning/Deep-Learning-VQA/ssl/output/backbone-resnet50-0.9041/byol_best.pth'\n",
    "model.load_state_dict(torch.load(path, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50()\n",
    "backbone = nn.Sequential(*list(resnet50.children())[:-1])\n",
    "backbone.load_state_dict(\n",
    "    torch.load('/Users/louis/Files/deep-learning/Deep-Learning-VQA/ssl/output/backbone-resnet50-0.9041/resnet50_best.pth', map_location='cpu'), \n",
    "    strict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.segmentation.fcn_resnet50(\n",
    "    num_classes=49, \n",
    "    aux_loss=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('/Users/louis/Files/deep-learning/Deep-Learning-VQA/ssl/output/backbone-resnet50-0.9041/resnet50_best.pth', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_dir = '/Users/louis/Files/deep-learning/Deep-Learning-VQA/ssl/output/backbone-resnet50-0.9041/resnet50_best.pth'\n",
    "\n",
    "resnet = models.resnet50()\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-2])\n",
    "backbone.load_state_dict(\n",
    "    torch.load(backbone_dir, map_location='cpu'), \n",
    "    strict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "model_backbone_keys = list(model.backbone.state_dict().keys())\n",
    "backbone_keys = list(state_dict.keys())\n",
    "\n",
    "key_dict = {backbone_keys[i]: model_backbone_keys[i] for i in range(len(backbone_keys))}\n",
    "\n",
    "adapted_dict = {key_dict[k] : v for k, v in state_dict.items()}\n",
    "\n",
    "adapted_dict = OrderedDict(adapted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backbone.load_state_dict(adapted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backbone.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50()\n",
    "backbone = nn.Sequential(*list(resnet50.children())[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.zeros((1, 3, 160, 240))\n",
    "y = backbone(X)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "180 * 30 / 60**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_resnet = models.segmentation.fcn_resnet50(num_classes=49, aux_loss=True)\n",
    "\n",
    "x = torch.zeros((1, 3, 160, 240))\n",
    "fcn_resnet(x)['out'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "        fcn_resnet = models.segmentation.fcn_resnet50(num_classes=49, aux_loss=True)\n",
    "        self.backbone = backbone\n",
    "        self.fcn_head = nn.Sequential(\n",
    "            fcn_resnet.classifier,\n",
    "            nn.ConvTranspose2d(49, 49, kernel_size=16, padding=4, stride=8)\n",
    "        )\n",
    "        self.fcn_head_aux = nn.Sequential(\n",
    "            fcn_resnet.aux_classifier,\n",
    "            nn.ConvTranspose2d(49, 49, kernel_size=16, padding=4, stride=8)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)         \n",
    "        x1 = x['out']  # (B, 2048, 20, 30)\n",
    "        x2 = x['aux']  # (B, 1024, 20, 30)\n",
    "        y = {}\n",
    "        y['out'] = self.fcn_head(x1)\n",
    "        y['aux'] = self.fcn_head_aux(x2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = nn.Sequential(*list(models.resnet50().children())[:-2])\n",
    "model = FCN(backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.888888888888889"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20 * 700 / 60**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/louis/Files/deep-learning/Deep-Learning-VQA/segmentation/output/fcn_resnet50_jaccard_0.9204/fcn_resnet50_best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "fcn = models.segmentation.fcn_resnet50(num_classes=49, aux_loss=True)\n",
    "\n",
    "fcn.load_state_dict(torch.load(path, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/louis/Files/deep-learning/Deep-Learning-VQA/segmentation/output/fcn_resnet50_jaccard_0.9204/'\n",
    "torch.save(fcn.classifier.state_dict(), path + 'classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(fcn.aux_classifier.state_dict(), path + 'aux_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
