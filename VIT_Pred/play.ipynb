{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.models.segmentation import fcn_resnet50\n",
    "from torchvision.transforms import transforms\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('./backbone/resnet50_best.pth', map_location='cpu')\n",
    "resnet = fcn_resnet50()\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "backbone.load_state_dict(state_dict)\n",
    "backbone = backbone[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = fcn_resnet50()\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_model' from 'utils' (/Users/brettb/Desktop/Deep_Learning/Final Project/Video-Instance-Segmentation-with-SSL/VIT_Pred/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m create_model\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'create_model' from 'utils' (/Users/brettb/Desktop/Deep_Learning/Final Project/Video-Instance-Segmentation-with-SSL/VIT_Pred/utils.py)"
     ]
    }
   ],
   "source": [
    "from utils import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = Image.open('/Users/brettb/Desktop/Deep_Learning/Final Project/Video-Instance-Segmentation-with-SSL/small_dataset/unlabeled/video_4000/image_0.png').convert(\"RGB\")\n",
    "img2 = Image.open('/Users/brettb/Desktop/Deep_Learning/Final Project/Video-Instance-Segmentation-with-SSL/small_dataset/unlabeled/video_4000/image_21.png').convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagenet transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )])\n",
    "img1_trns = transform(img1)\n",
    "img2_trns = transform(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img1_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img1_output\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img1_output' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "loss = nn.MSELoss()\n",
    "img1_trns = img1_trns.unsqueeze(0)\n",
    "img2_trns = img2_trns.unsqueeze(0)\n",
    "img1_output = backbone(img1_trns)\n",
    "img2_output = backbone(img2_trns)\n",
    "print(img1_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brettb/opt/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model = Predictor(in_size=(11,2048,20,30), num_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "Predictor                                     [1, 2048, 20, 30]         3,379,200\n",
       "├─Linear: 1-1                                 [1, 6600, 512]            1,049,088\n",
       "├─Sequential: 1-2                             [1, 6600, 512]            --\n",
       "│    └─TransformerBlock: 2-1                  [1, 6600, 512]            --\n",
       "│    │    └─LayerNorm: 3-1                    [1, 6600, 512]            1,024\n",
       "│    │    └─MultiHeadSelfAttention: 3-2       [1, 6600, 512]            1,049,088\n",
       "│    │    └─LayerNorm: 3-3                    [1, 6600, 512]            1,024\n",
       "│    │    └─Sequential: 3-4                   [1, 6600, 512]            2,099,712\n",
       "│    └─TransformerBlock: 2-2                  [1, 6600, 512]            --\n",
       "│    │    └─LayerNorm: 3-5                    [1, 6600, 512]            1,024\n",
       "│    │    └─MultiHeadSelfAttention: 3-6       [1, 6600, 512]            1,049,088\n",
       "│    │    └─LayerNorm: 3-7                    [1, 6600, 512]            1,024\n",
       "│    │    └─Sequential: 3-8                   [1, 6600, 512]            2,099,712\n",
       "│    └─TransformerBlock: 2-3                  [1, 6600, 512]            --\n",
       "│    │    └─LayerNorm: 3-9                    [1, 6600, 512]            1,024\n",
       "│    │    └─MultiHeadSelfAttention: 3-10      [1, 6600, 512]            1,049,088\n",
       "│    │    └─LayerNorm: 3-11                   [1, 6600, 512]            1,024\n",
       "│    │    └─Sequential: 3-12                  [1, 6600, 512]            2,099,712\n",
       "├─Linear: 1-3                                 [1, 6600, 2048]           1,050,624\n",
       "├─ReLU: 1-4                                   [1, 6600, 2048]           --\n",
       "├─Linear: 1-5                                 [1, 2048, 600]            3,960,600\n",
       "===============================================================================================\n",
       "Total params: 18,892,056\n",
       "Trainable params: 18,892,056\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 15.51\n",
       "===============================================================================================\n",
       "Input size (MB): 54.07\n",
       "Forward/backward pass size (MB): 1037.11\n",
       "Params size (MB): 62.05\n",
       "Estimated Total Size (MB): 1153.23\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(1, 11, 2048, 20, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
