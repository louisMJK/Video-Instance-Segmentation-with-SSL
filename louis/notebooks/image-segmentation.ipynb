{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "import torchmetrics\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../dataset/'\n",
    "train_dir = data_dir + 'train/'\n",
    "val_dir = data_dir + 'val/'\n",
    "unlabel_dir = data_dir + 'unlabeled/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(data_dir + \"train/video_0/image_21.png\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = np.load(data_dir + \"train/video_0/mask.npy\")\n",
    "print(masks.shape)\n",
    "plt.imshow(masks[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.load(data_dir + \"train/video_0/mask.npy\")[0]\n",
    "obj_ids = np.unique(mask)  # instances are encoded as different colors\n",
    "obj_ids = obj_ids[1: ]     # remove background (1st id)\n",
    "print(obj_ids)\n",
    "\n",
    "num_objs = len(obj_ids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, root='../../dataset/unlabeled/', transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.vid_list = sorted(os.listdir(root))\n",
    "        self.img_list = ['image_' + str(i) + '.png' for i in range(22)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.vid_list) * 22\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        vid_idx = idx // 22\n",
    "        img_idx = idx % 22\n",
    "        # load images (unlabeled)\n",
    "        img_path = os.path.join(self.root, self.vid_list[vid_idx], self.img_list[img_idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
